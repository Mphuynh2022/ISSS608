---
title: "Take Home Exercise 02"
author: "Huynh Minh Phuong"
execute:
  echo: true
  eval: true
  warning: false
---

# Overview

Oceanus has enlisted FishEye International's assistance in identifying potentially illegal fishing companies. FishEye's analysts were provided with import/export data for Oceanus' marine and fishing sectors, but the data was incomplete. To aid their analysis, FishEye transformed the trade data into a knowledge graph to understand business relationships, specifically to combat illegal, unreported, and unregulated (IUU) fishing and protect affected marine species. While node-link diagrams provided a high-level overview of the knowledge graph, FishEye now seeks visualizations that offer more detailed patterns about entities within the graph. The analysis consists of two main parts.

Firstly, FishEye aims to visualize temporal patterns to determine if companies engaging in illegal fishing activities have reemerged under different names after shutting down. They seek assistance in comparing the activities of these companies over time.

Secondly, FishEye has employed various tools, including artificial intelligence, to reason on the knowledge graph and propose additional links to expand the dataset. They have presented 12 groups of link suggestions and require aid in evaluating the reliability of these tools for completing the graph. FishEye is particularly interested in identifying new temporal patterns or anomalies that arise when new links are added.

We aim to use visual analytics to help FishEye identify companies that may be engaged in illegal fishing.

# Data set

The graph is structured in a JSON format designed to align with d3's node-link format and ensure compatibility with networkx.node_link_graph. At the top level, it consists of a dictionary containing graph-level properties, indicated by keys such as "directed," "multigraph," and "graph." The "nodes" and "links" keys each hold a dictionary of nodes and links, respectively.

For nodes, the entries must include a unique "id" key for each node. As for links, they consist of "source" and "target" keys, referring to the node id values. Any additional keys provided within the node and link dictionaries serve as attributes for those specific nodes or links.

Node Attributes:

-   id -- Name of the company that originated (or received) the shipment

-   shpcountry -- Country the company most often associated with when shipping

-   rcvcountry -- Country the company most often associated with when receiving

-   dataset -- Always 'MC2'

Edge Attributes:

-   arrivaldate -- Date the shipment arrived at port in YYYY-MM-DD format.

-   hscode -- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.

-   valueofgoods_omu -- Customs-declared value of the total shipment, in Oceanus Monetary Units (OMU)

-   volumeteu -- The volume of the shipment in 'Twenty-foot equivalent units', roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)

-   weightkg -- The weight of the shipment in kilograms (if known)

-   dataset -- Always 'MC2'

-   type -- Always 'shipment' for MC2

-   generated_by -- Name of the program that generated the edge. (Only found on 'bundle' records.)

## Load packages

The main packages for plotting graphs are: **igraph, tidygraph, ggraph, visNetwork, sf, sfnetworks**. The rest of the packages are for data wrangling.

```{r}
pacman::p_load(igraph,tidygraph,sf,sfnetworks,ggraph,visNetwork,sftime,ggmap,lubridate,clock,tmap,readr,ggplot2,tidyverse,graphlayouts,assertthat,purrr, jsonlite, zoo)
```

## Import data

Use `fromJson` from package **jsonlite** to import main graph data from json file format

```{r}
MC2<-fromJSON("data/mc2_challenge_graph.json")
```

Import bundle data. Each bundle represents the output of an AI program for link inference. Each bundle represents a list of potential edges to add to the main graph. The challenge is to decide WHICH of these bundles should be used.

```{r}
carp<-fromJSON("data/bundles/carp.json")
catfish<-fromJSON("data/bundles/catfish.json")
chub_mackerel<-fromJSON("data/bundles/chub_mackerel.json")
cod<-fromJSON("data/bundles/cod2.json")
herring<-fromJSON("data/bundles/herring.json")
lichen<-fromJSON("data/bundles/lichen.json")
mackerel<-fromJSON("data/bundles/mackerel.json")
pollock<-fromJSON("data/bundles/pollock.json")
salmon<-fromJSON("data/bundles/salmon.json")
salmon_wgl<-fromJSON("data/bundles/salmon_wgl.json")
shark<-fromJSON("data/bundles/shark.json")
tuna<-fromJSON("data/bundles/tuna.json")
```

## Extract node information for the main graph

We will ignore the *dataset* column and use `select` to select *id, shipping country and receiving country* information. Use `glimpse` to view the data.

```{r}
MC2_nodes <- as_tibble(MC2$nodes) %>% 
  select(id, shpcountry,rcvcountry)

glimpse(MC2_nodes)
```

Use `as.factor` to convert the character data type to factor.

```{r}
MC2_nodes$id <-as.factor(MC2_nodes$id)
MC2_nodes$shpcountry<-as.factor(MC2_nodes$shpcountry)
MC2_nodes$rcvcountry<-as.factor(MC2_nodes$rcvcountry)

summary(MC2_nodes)
```

::: callout-note
We observed many NA in the shpcountry and rcvcountry columns. Since we are unable to infer the values for these columns, we need to remove rows with NA values.
:::

We use `group_by` to check for each company id how many different *shipcountry* and *rcvcounty* are available to identify the overall trend. Each company only ship to 1 receiving country and ship from 1 shipping country.

```{r}
count<-MC2_nodes %>% 
  group_by(id) %>% 
  summarise(no_shpcountry=n_distinct(shpcountry),
            no_rcvcountry=n_distinct(rcvcountry)) 

summary(count)
```

## Extract edge information for the main graph

We only considered edges information of nodes in MC2_nodes and used `filter` to filter out the edges for those nodes. We ignored the *dataset* and *type* column and used `select` to select the rest of the attributes of edges of the main graph. Used `glimpse` to view the data.

```{r}
MC2_edges <-as_tibble(MC2$links) %>%
  select(source, target, arrivaldate,hscode,weightkg,volumeteu,valueofgoodsusd,valueofgoods_omu) %>% 
  distinct()

glimpse(MC2_edges)
```

::: callout-note
Wrong data types for *arrivaldate* as well as other character type data need to be converted.
:::

We used `as.factor` to convert *source, target, hscode*. `mutate` and `ymd` were used to convert *arrival date* data type to date and extract day of the week information from the date with `wday`

```{r}
MC2_edges$source<-as.factor(MC2_edges$source)
MC2_edges$target<-as.factor(MC2_edges$target)

MC2_edges<-MC2_edges %>% 
  mutate(arrivaldate = ymd(arrivaldate)) %>% 
  mutate(weekday = wday(arrivaldate,
                        label = TRUE,
                        abbr = FALSE)) %>% 
  mutate(monthyear=as.yearmon(arrivaldate)) %>% 
  mutate(year=year(arrivaldate))
glimpse(MC2_edges)
```

`summary` was used to get a sense of data distribution. Since *volumeteu, valuesofgoods_usd* and *valueofgoods_omu* mostly contain 0 or NA values, we can disregard these columns in the analysis. We also observed that Friday seems to have the highest number of shipments while Wednesday has the lowest number of shipments.

```{r}
summary(MC2_edges)
```

## Filter out irrelevant hscode

We use `n_distinct()` to check the number of hscode available in the dataset. There are many hscode values that are not relevant to our project. For example, hscode 470710 is for shipment of paper or paperboard. hscode that are relevant to our fish data will include only those that starts with:

-   "301": Live Fish

-   "302: Fresh or chilled fish exclude fish fillets and fish meat in 304

-   "303": Frozen fish

-   "304": Fish fillets and fish meat (fresh, chilled or frozen)

-   "305": Fish, dried, salted or in brine

sed `substr()` to extract the first 3 digit from hscode and then filter rows with only the hscode that starts with 301, 302, 303, 304, 305.

```{r}
n_distinct(MC2_edges$hscode)
  
```

```{r}
MC2_edges_filtered<-MC2_edges %>% 
  mutate(sub_hscode=substr(hscode,1,3)) %>% 
  filter(sub_hscode %in% c("301","302","303","304","305"))

MC2_edges_filtered$sub_hscode<-as.factor(MC2_edges_filtered$sub_hscode)

summary(MC2_edges_filtered$sub_hscode)
```

Since we have very few 301 and 302 code type, we will focus on 303 and 304 hscodes. We calculated the weight by using frequency count of the number of links by *source, target and monthyear*. We also calculate the average *weightkg* for the aggregated data.

```{r}
MC2_edges_aggregated<-MC2_edges_filtered %>%
  filter(sub_hscode %in% c("303", "304")) %>%
  group_by(source, target, monthyear) %>% 
  summarise(weight=n(),
            weightkg=mean(weightkg)) %>% 
  filter(weight>20) %>% 
  ungroup()

summary(MC2_edges_aggregated)
```

::: callout-note
Weight has a right skewed distribution with mean of 8 and median of 2. We are only interested in shipments with unusual higher frequency (weight\>20). We can choose to look at only *source* nodes that have shipped the highest number of shipments and *target* nodes that have received the highest number of shipments
:::

## Prepare nodes data with top sources and targets

We prepare the nodes that are in the aggregated data source and target.

```{r}
id1 <- MC2_edges_aggregated %>%
  select(source) %>%
  rename(id = source)
id2 <- MC2_edges_aggregated %>%
  select(target) %>%
  rename(id = target)
MC2_nodes_aggregated <- rbind(id1, id2) %>%
  distinct()
MC2_nodes_aggregated<-merge(MC2_nodes_aggregated, MC2_nodes, by="id")

MC2_nodes_aggregated
```

# Data Visualization

## Temporal analysis

```{r}
source_trend<-MC2_edges%>%
  filter(sub_hscode %in% c("303","304")) %>% 
  group_by(source,year) %>%
  summarise(weight=n(),
            weightkg=sum(weightkg)) %>%
  arrange(year)
source_trend
```

```{r}
source_trend<-source_trend %>% 
  group_by(source) %>%
  mutate(weightkg_pct_change=round((weightkg/lag(weightkg)-1)*100,0)) %>% 
  mutate(weight_pct_change=round((weight/lag(weight)-1)*100,0)) %>% 
  mutate(count=n()) %>% 
  filter(count==7)

summary(source_trend)
```

```{r}
  ggplot(source_trend, aes(x = year, y = weight_pct_change,
             colour=source))+
  geom_point()+
  geom_line()+
  theme(legend.position="none")
```

```{r}
ggplot(source_trend, aes(x = year, y = weightkg_pct_change,
             colour=source))+
  geom_point()+
  geom_line()+
  theme(legend.position="none")
```

```{r}
target_trend<-MC2_edges%>%
  filter(sub_hscode %in% c("303","304")) %>% 
  group_by(target,year) %>%
  summarise(weight=n(),
            weightkg=sum(weightkg)) %>%
  arrange(year)
target_trend
```

```{r}
target_trend<-target_trend %>% 
  group_by(target) %>%
  mutate(weightkg_pct_change=round((weightkg/lag(weightkg)-1)*100,0)) %>% 
  mutate(weight_pct_change=round((weight/lag(weight)-1)*100,0)) %>% 
  mutate(count=n()) %>% 
  filter(count==7)

summary(target_trend)
```

```{r}
  ggplot(target_trend, aes(x = year, y = weight_pct_change,
             colour=target))+
  geom_point()+
  geom_line()+
  theme(legend.position="none")
```

```{r}
  ggplot(target_trend, aes(x = year, y = weightkg_pct_change,
             colour=target))+
  geom_point()+
  geom_line()+
  theme(legend.position="none")
```

```{r}
source_target_trend<-MC2_edges%>%
  filter(sub_hscode %in% c("303","304")) %>% 
  group_by(source,target, year) %>%
  summarise(weight=n(),
            weightkg=sum(weightkg)) %>%
  arrange(year)

summary(source_target_trend)
```

## Visualize the main graph

```` ```{r} # MC2_graph<-tbl_graph(nodes=MC2_nodes_aggregated, #                          edges=MC2_edges_aggregated, #                          directed = TRUE) ````

```{r}
# MC2_graph
```

```{r}
# MC2_graph %>%
#   activate(edges) %>% 
#   arrange(desc(weight))
```

```{r warning=FALSE}
# # |fig-width: 100
# # |fig-height: 100
# g<-MC2_graph %>%
#   ggraph(layout = "nicely")+
#   geom_edge_link(aes(width=weight), alpha=0.2)+
#   scale_edge_width(range = c(0.1, 5))+
#   geom_node_point()+
#   theme(legend.position = 'bottom')
#   
# # g+facet_nodes(~year)+
# #   th_foreground(foreground = "grey80",  
# #                 border = TRUE) +
# #   theme(legend.position = 'bottom')
# 
# g
```

```{r}
# top_MC2_edges_aggregated<-top_MC2_edges %>% 
#   rename(from=source) %>% 
#   rename(to=target)
# 
# top_MC2_edges_aggregated
# 
# top_MC2_nodes<-top_MC2_nodes %>% 
#   rename(group=year)
```

```{r}
visNetwork(top_MC2_nodes,
           top_MC2_edges_aggregated) %>% 
  visIgraphLayout(layout = "layout_with_fr") %>% 
  visEdges(arrows = "to", 
           smooth = list(enabled = TRUE, 
                         type = "curvedCW")) %>%
  visLegend() %>% 
  visLayout(randomSeed=123) %>% 
  visOptions(highlightNearest = TRUE,
             nodesIdSelection = TRUE)
```

```{r}
carp_edges<-as_tibble(carp$links) %>%   
  mutate(ArrivalDate = ymd(arrivaldate)) %>%
  mutate(Year = year(ArrivalDate)) %>%
  mutate(sub_hscode=substr(hscode,1,3)) %>% 
  mutate(hscode=as.factor(hscode)) %>%
  mutate(sub_hscode=as.factor(sub_hscode)) %>% 
  select(source, target, ArrivalDate, Year, hscode, weightkg, sub_hscode) %>% 
  distinct()
summary(carp_edges$sub_hscode)
```

```{r}
catfish_edges<-as_tibble(catfish$links) %>%   
  mutate(ArrivalDate = ymd(arrivaldate)) %>%
  mutate(Year = year(ArrivalDate)) %>%
  mutate(sub_hscode=substr(hscode,1,3)) %>% 
  mutate(hscode=as.factor(hscode)) %>%
  mutate(sub_hscode=as.factor(sub_hscode)) 
 
summary(catfish_edges$sub_hscode)
```

## Community Dectection

group_components()
